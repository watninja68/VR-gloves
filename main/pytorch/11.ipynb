{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "\n",
    "def load_data(input_file, output_file, expected_landmarks=21):\n",
    "    # Load input data\n",
    "    input_df = pd.read_csv(input_file, header=None)\n",
    "    \n",
    "    # Convert each column of input data into a tensor and concatenate into a single tensor\n",
    "    input_tensors = [torch.FloatTensor(input_df[col].values) for col in input_df.columns]\n",
    "    inputs = torch.stack(input_tensors, dim=1)  # Stack columns into a single tensor\n",
    "    \n",
    "    # Load the output data as a DataFrame\n",
    "    output_df = pd.read_csv(output_file, header=None)\n",
    "    \n",
    "    # Define a pattern to extract numbers from landmark strings\n",
    "    pattern = r'Landmark_\\d+:\\s*\\(([-\\d.]+),\\s*([-\\d.]+),\\s*([-\\d.]+)\\)'\n",
    "    \n",
    "    # Process each row in the output DataFrame\n",
    "    all_landmarks = []\n",
    "    for idx, row in output_df.iterrows():\n",
    "        row_data = ','.join(map(str, row))  # Convert all elements to strings before joining\n",
    "        matches = re.findall(pattern, row_data)\n",
    "        if not matches:\n",
    "            raise ValueError(f\"No valid landmark data found in row {idx}: {row_data}\")\n",
    "        \n",
    "        if len(matches) != expected_landmarks:\n",
    "            raise ValueError(f\"Expected {expected_landmarks} landmarks, but found {len(matches)} in row {idx}\")\n",
    "        \n",
    "        landmarks = [float(coord) for match in matches for coord in match]\n",
    "        all_landmarks.append(landmarks)\n",
    "    \n",
    "    # Convert list of landmarks into a tensor\n",
    "    targets = torch.FloatTensor(all_landmarks)\n",
    "    \n",
    "    if targets.shape[1] != expected_landmarks * 3:\n",
    "        raise ValueError(f\"Inconsistent number of coordinates. Expected {expected_landmarks * 3}, but got {targets.shape[1]}\")\n",
    "    \n",
    "    return inputs, targets\n",
    "\n",
    "# Usage example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LandmarkPredictor, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.bn(self.hidden(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=1000, lr=0.01):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        running_mae = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_mae += torch.mean(torch.abs(outputs - targets)).item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_mae = running_mae / len(train_loader)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy (MAE): {epoch_mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing data: Expected 21 landmarks, but found 20 in row 1650\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        inputs, targets = load_data(\"hand_landmarks.csv\", \"frame_landmarks.csv\")\n",
    "        print(f\"Inputs shape: {inputs.shape}\")\n",
    "        print(f\"Targets shape: {targets.shape}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing data: {e}\")\n",
    "    input_size = inputs.shape[1]  \n",
    "    hidden_size = 64\n",
    "    output_size = targets.shape[1] \n",
    "    print(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing data: Expected 21 landmarks, but found 20 in row 1650\n",
      "Epoch [10/1000], Loss: 0.0049, Accuracy (MAE): 0.0460\n",
      "Epoch [20/1000], Loss: 0.0043, Accuracy (MAE): 0.0427\n",
      "Epoch [30/1000], Loss: 0.0042, Accuracy (MAE): 0.0426\n",
      "Epoch [40/1000], Loss: 0.0041, Accuracy (MAE): 0.0418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[163], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m LandmarkPredictor(input_size, hidden_size, output_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m train_model(model, train_loader)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[0;32m     21\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/landmark_predictor.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[161], line 10\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, epochs, lr)\u001b[0m\n\u001b[0;32m      7\u001b[0m running_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m---> 10\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        inputs, targets = load_data(\"hand_landmarks.csv\", \"frame_landmarks.csv\")\n",
    "        print(f\"Inputs shape: {inputs.shape}\")\n",
    "        print(f\"Targets shape: {targets.shape}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing data: {e}\")\n",
    "    input_size = inputs.shape[1]  \n",
    "    hidden_size = 64\n",
    "    output_size = targets.shape[1]  # Change this to use the second dimension\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = TensorDataset(inputs, targets)\n",
    "    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    model = LandmarkPredictor(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "    train_model(model, train_loader)\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), \"./models/landmark_predictor.pth\")\n",
    "    print(\"Model trained and saved as 'landmark_predictor.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
